{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"assignment\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.parquet(\"C:/Users/Tejashree/Downloads/Redhat Assignment/consumerInternet.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.load(\"C:/Users/Tejashree/Downloads/Redhat Assignment/startup.csv\", format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.union(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sr_No',\n",
       " 'Date',\n",
       " 'Startup_Name',\n",
       " 'Industry_Vertical',\n",
       " 'SubVertical',\n",
       " 'City',\n",
       " 'Investors_Name',\n",
       " 'InvestmentnType',\n",
       " 'Amount_in_USD',\n",
       " 'Remarks']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"startup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many startups are there in Pune City?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|total_startups|\n",
      "+--------------+\n",
      "|          2459|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(distinct Startup_name) as total_startups FROM startup\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many startups in Pune got their Seed/ Angel Funding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|total_startups|\n",
      "+--------------+\n",
      "|          1435|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(distinct Startup_name) as total_startups FROM startup where lower(InvestmentnType) like '%seed%' or lower(InvestmentnType) like '%angel%' \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the total amount raised by startups in Pune City? Hint - use regex_replace to get rid of null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "| total_amount|\n",
      "+-------------+\n",
      "|9.788800999E9|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select sum(regexp_replace(amount, '[^0-9]', 0)) as total_amount from (select CAST(regexp_replace(Amount_in_USD, ',', '') AS DOUBLE) as amount from startup where lower(city) = 'pune') where amount is not null\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the top 5 Industry_Vertical which has the highest number of startups in India?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+\n",
      "|industry_vertical|startups|\n",
      "+-----------------+--------+\n",
      "|Consumer Internet|     835|\n",
      "|       Technology|     453|\n",
      "|        eCommerce|     162|\n",
      "|       Healthcare|      70|\n",
      "|        ECommerce|      59|\n",
      "+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select industry_vertical, count(distinct startup_name) as startups from startup where industry_vertical != 'nan' group by industry_vertical order by startups desc limit 5\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the top Investor(by amount) of each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---------------+\n",
      "|      investors_name|year|   total_amount|\n",
      "+--------------------+----+---------------+\n",
      "|       SAIF Partners|2015|          1.4E9|\n",
      "|     Kalaari Capital|2016|         1.24E9|\n",
      "|Bennett, Coleman ...|2017|         1.55E9|\n",
      "|Avendus Finance P...|2018|          9.7E8|\n",
      "|             FinTech|2019|1.0741126507E10|\n",
      "|Sequoia Capital I...|2020|  1.083588607E9|\n",
      "+--------------------+----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select investors_name, year, total_amount from (select investors_name, year, total_amount, rank() over (partition by year order by total_amount desc) as rank from \n",
    "            (select investors_name, year, sum(regexp_replace(amount, '[^0-9]', 0)) as total_amount from\n",
    "                (select Investors_Name, year(TO_DATE(CAST(UNIX_TIMESTAMP(date, 'dd/MM/yyyy') AS TIMESTAMP))) as year, \n",
    "                        CAST(regexp_replace(Amount_in_USD, ',', '') AS DOUBLE) as amount \n",
    "                        from startup where date != '01/07/015' and investors_name != 'N/A') \n",
    "                where year is not null group by investors_name, year)) where rank = 1 order by year asc\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the top startup(by amount raised) from each city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+-------------+\n",
      "|        startup_name|             city|amount_raised|\n",
      "+--------------------+-----------------+-------------+\n",
      "|                Zefo|        Bangalore|       1.52E9|\n",
      "|            Uniphore|         Taramani|    3080807.0|\n",
      "|    Karma Healthcare|          Udaipur|        5.0E7|\n",
      "|         Convegenius|Noida / Singapore|        3.0E7|\n",
      "|        Lenskart.com|        Faridabad|     203108.0|\n",
      "|Vogo Automotive P...|        Karnataka|      3.584E8|\n",
      "|               GOQii|       Menlo Park|      40508.0|\n",
      "|            Uniphore|        Palo Alto|      50107.0|\n",
      "|         VST Travels|           Kerala|    2700000.0|\n",
      "|               CBREX|      Mumbai / NY|        2.0E7|\n",
      "|           Active.ai|        Singapore|        3.5E8|\n",
      "|               Qriyo|          Jodhpur|        1.6E7|\n",
      "|           Elucidata|Delhi & Cambridge|        1.7E8|\n",
      "|           Pastiwala|         Vadodara|        4.0E8|\n",
      "|             Mazkara|     Pune / Dubai|        1.0E8|\n",
      "|        CreditMantri|          Chennai|       1.01E9|\n",
      "|     EduAce Services|          Lucknow|        1.0E8|\n",
      "|         Matrubharti|             null|    3000000.0|\n",
      "|            Zendrive|    San Francisco|      30707.0|\n",
      "|           DawaiLelo|         Varanasi|    5200000.0|\n",
      "+--------------------+-----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select startup_name, city, amount_raised from (select startup_name, city, amount_raised, rank() over (partition by city order by amount_raised desc) as rank from \n",
    "            (select startup_name, city, sum(regexp_replace(amount, '[^0-9]', 0)) as amount_raised from\n",
    "                (select startup_name, city, CAST(regexp_replace(Amount_in_USD, ',', '') AS DOUBLE) as amount \n",
    "                        from startup) group by  startup_name, city) where  amount_raised is not null) where rank <= 1\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
